<!DOCTYPE html>
<!-- saved from url=(0018)https://slrtp.com/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>SLRTP 2022: Sign Language Recognition, Translation and Production Workshop</title>
		  
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta name="keywords" content="ECCV, Sign Language Recognition, Sign Language Translation, Sign Language Production, Workshop, ECCV Workshop">
        <meta name="description" content="ECCV 2022 Workshop on Sign Language Recognition, Translation and Production.">
        <meta name="author" content="Gul Varol">
        <meta name="viewport" content="width=device-width, initial-scale=0.75">
        <meta http-equiv="Cache-control" content="public" max-age="86400">

		<!--== CSS Files ==-->
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/bootstrap.min.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/style.min.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/animate.min.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/font-awesome.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/flexslider.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/fancySelect.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/owl.carousel.css" rel="stylesheet" media="screen">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/responsive.css" rel="stylesheet" media="screen">

		<!--== Google Fonts ==-->
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/css" rel="stylesheet" type="text/css">
		<link href="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/css(1)" rel="stylesheet" type="text/css">
		
	<script type="text/javascript" charset="UTF-8" src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/common.js"></script><script type="text/javascript" charset="UTF-8" src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/util.js"></script></head>
	<body>
		<div id="home"></div>
		<header id="header" class="header" data-stellar-ratio="0.5" style="transform: translate3d(0px, 649.5px, 0px);">

			<!--== Preloader ==-->
			<div id="preloader" class="ready"><div class="preloader"></div></div>

			<!--== Caption ==-->
            
			<div class="header-caption" data-stellar-ratio="2" style="transform: translate3d(0px, -1299px, 0px);">
				<div class="container">
					<div class="box">
                        <p style="color:white;">In conjunction with ECCV 2022</p>
                        <!-- <h2w>In conjunction with ECCV 2022<br></h2w>
						<span class="typed">virtually</span><span class="typed-cursor">|</span> -->
					</div>
				</div>
			</div>

			<!--== Header Background ==-->
			<div id="header-background" class="header-background">
				<ul class="slides">
                    <li class="flex-active-slide" style="width: 100%; float: left; margin-right: -100%; position: relative; display: block; z-index: 2; opacity: 1;"><img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/slrtp_black.png" alt="ECCV Workshop 2020 - SLRTP" draggable="false" style="margin-left: -718.5px; margin-top: -539px;"></li>
				</ul>
			</div>

		</header>

		<div id="navigation-wrap" class="navigation-wrap sticky">
			<div id="navigation" class="navigation">
				<div class="container">
					<nav class="navbar navbar-custom" role="navigation">

						<div class="navbar-header">
							<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#menu">
								<span class="sr-only">Toggle navigation</span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
						</div>

						<!--== Site Menu ==-->
						<div class="collapse navbar-collapse" id="menu">
							<ul class="nav navbar-nav">
								<li class=""><a href="https://slrtp.com/#home">Home</a></li>
                                <li class=""><a href="https://slrtp.com/#challenge">Challenge</a></li>
                                <li class=""><a href="https://slrtp.com/#dates">Dates</a></li>
                                <li class=""><a href="https://slrtp.com/#keynotes">Keynotes</a></li>
                                <li class=""><a href="https://slrtp.com/#schedule">Schedule</a></li>
                                
                                <li class=""><a href="https://slrtp.com/#organizers">Organizers</a></li>
							</ul>
						</div>

					</nav>
				</div>
			</div>
		</div>
        
		<div class="container content">     

		<!--===============================-->
			<!--== About ======================-->
			<!--===============================-->

			<section id="about">
				<div class="row">
					<div class="col-sm-12 col-md-12">
						<p>Sign languages are spatial-temporal languages and constitute a key form of communication for Deaf communities. Recent progress in fine-grained gesture and
                            action classification, machine translation and image captioning, point to the
                            possibility of automatic sign language understanding becoming a reality. The
                            study of isolated sign recognition has a rich history in the computer vision community stretching back over thirty years. Thanks to the recent availability of
                            larger datasets, researchers are now focusing on continuous sign language recognition, sentence alignment to continuous signing and sign language translation.
                            Advances in generative networks are also enabling progress on sign language
                            production, where written language is converted into sign language video.
                            </p>

                        <p> The "Sign Language Recognition, Translation & Production" (SLRTP) Workshop brings together researchers working on different aspects of vision-based sign language research (including body posture, hands and face) and sign language linguists. The focus of this workshop is to broaden participation in sign language research from the computer vision community. We hope to identify
                            important future research directions, and to cultivate collaborations.
                            The workshop will consist of invited talks and also a challenge with three
                            tracks: individual sign recognition; English sentence to sign sequence alignment; and sign spotting.</p>
					</div>
				</div>
			</section>

            <section id="challenge">
                <div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Challenge</b></h2>
						</div>
					</div>
                    <p>The challenge will have <u>three</u> tracks. 
                        The first track is (1) <b>sign recognition</b> from
                        co-articulated signing for a large number of classes – the task is to classify individual signs in 
                        continuous signing sequences given their approximate temporal extent. This
                        should encourage discussion on how to best (i) exploit complementary signals
                        across different modalities and articulators, (ii) model temporal information,
                        (iii) account for long-tailed distributions.</p>
                    
                    <p>The second track is for (2) <b>alignment</b>
                        of spoken language sentences to continuous signing – the task of determining
                        the temporal extent of a signing sequence, given its English translation. This
                        is a key step for automatically constructing a parallel corpus for sign language
                        translation. This should encourage discussion on how to best model video and
                        text jointly.</p>
                    
                    <p>The final track is (3) <b>sign spotting</b> : here the task is to identify whether and 
                        when a sign is performed in a given window of continuous signing. Sign spotting has a
                         range of applications including: indexing of signing content to enable efficient search 
                         and “intelligent fast-forward” to topics of interest, automatic sign language dataset 
                         construction and “wake-word” recognition for signers.</p>
                    
                    <p>Teams that submit their results to the challenges will also be required to submit a description of their systems. At the workshop, we will invite presentations
                        from the challenge winners.</p>
                    
                    <div class="row">
                        <div class="col-sm-12">
                            <div class="content-tabs">
                                <div class="tab-content">
                                    <div class="tab-pane fade in active" id="tab1">
                                        <ul class="accordion">
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 1
                                                    </span>
                                                    <p class="accordion-title"> <b>Sign recognition</b> from co-articulated signing
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        More details coming soon.
                                                    <p></p>
                                                </div>
                                            </li>
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 2
                                                    </span>
                                                    <p class="accordion-title"> <b>Alignment</b> of spoken language sentences to continuous signing
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        More details coming soon.
                                                    <p></p>
                                                </div>
                                            </li>
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 3
                                                    </span>
                                                    <p class="accordion-title"> <b>Sign spotting </b> in continuous co-articulated signing
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        More details coming soon.
                                                    <p></p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

				</div>
                
            </section>
            

        <section id="dates">
                <div class="row">
                    <div class="col-sm-12 col-md-2">
                        <div class="section-header text-left">
                            <h2><b>Dates</b></h2>
                        </div>
                    </div>
                    <div class="col-sm-12 col-md-9">
                        <ul style="list-style-type:none">
                            <div class="divTable">
                            <div class="divTableBody">
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Challenge open: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>TBA, 2022</b></lti> </h4table></div>
                            </div>
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Challenge close: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>TBA, 2022</b></lti> </h4table></div>
							</div>
							<div class="divTableRow">
								<div class="divTableCell"><h4table>Winners announced: </h4table></div>
								<div class="divTableCell"><h4table><lti><b>TBA, 2022</b></lti> </h4table></div>
							</div>
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Workshop date: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>TBA, 2022</b></lti> </h4table></div>
                            </div>
                            </div>
						</ul>
                        <div class="row">
                </div>
            </section>
			<!--===============================-->
			<!--== Keynotes ===================-->
			<!--===============================-->
			<section id="keynotes" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Keynotes</b></h2>
						</div>
					</div>
				</div>

                <div class="row">
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/melissa-malzkuhn.jpg" alt="Melissa Malzkuhn">
							<div class="speaker-info">
								<h3>Melissa<br> <b>Malzkuhn</b></h3>
								<p>Founder<br> <i>Motion Light Lab</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://mezmalz.com/about" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/mark-wheatley.jpg" alt="Mark Wheatley">
							<div class="speaker-info">
								<h3>Mark<br> <b>Wheatley</b></h3>
								<p>Executive Director<br><i>European Union of the Deaf</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.edf-feph.org/profile/markwheatley/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/sarah-ebling.jpg" alt="Sarah Ebling">
							<div class="speaker-info">
								<h3>Sarah<br> <b>Ebling</b></h3>
								<p>Senior researcher<br><i>University of Zurich</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.cl.uzh.ch/de/people/team/compling/ebling.html" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jeff-mcwhinney.jpg" alt="Jeff McWhinney">
							<div class="speaker-info">
								<h3>Jeff<br> <b>McWhinney</b></h3>
								<p>Founder<br> <i>SignVideo</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.pragmaprojects.eu/deafenterprise.eu/index.php/deaf-entrepreneurs/country/item/jef" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
				<div class="row">
				</div>

			</section>
			<!--==========-->

			<!--===============================-->
			<!--== Schedule ===================-->
            <!--===============================-->
            
			<section id="schedule" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-left">
							<h2><b>Schedule</b></h2>
						</div>
					</div>
				</div>
				<div class="row">
					<div class="col-sm-12">
						<div class="content-tabs">
							<div class="tab-content">
								<div class="tab-pane fade in active" id="tab1">
									<ul class="accordion">
										<li>
											<a class="accordion-heading">
												<span class="schedule-time accent">
													TBA<sup></sup>
												</span>
												<h4 class="accordion-title"></h4>
											</a>
                                            <div class="accordion-body" style="display: none;">
												<p>
												</p>
											</div>
										</li> 

                                        <!-- <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    14<sup>10</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/bencie-woll.jpg" alt="Bencie Woll">
                                                </div>
                                                <p class="accordion-title">Invited talk by  <b>Bencie Woll</b>: <br> 
                                                    <i>Processing Sign Languages: Linguistic, Technological, and Cultural Challenges</i>
                                                </p>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													</p><h4><b>Bio</b></h4>
													Professor Bencie Woll has been involved in research on sign language for nearly 
													40 years, starting with research at the University of Bristol where she was a 
													co-founder of the Centre for Deaf Studies, pioneering research on the linguistics 
													of BSL and on Deaf Studies. She moved to City University London in 2005 to take up 
													the newly created Chair in Sign Language and Deaf Studies. From City she moved in 
													2005 to UCL, where she is Professor of Sign Language and Deaf Studies. In 2006, 
													together with colleagues at UCL and City, she founded DCAL, and served as Diector until 2016.

													Her research and teaching interests embrace a wide range of topics related to 
													sign language, including the linguistics of British Sign Language (BSL) and 
													other sign languages, the history and sociolinguistics of BSL and the Deaf community, 
													the development of BSL in young children, and sign language and the brain, including 
													developmental and acquired sign language impairments.
                                                <p></p>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/bencie-woll.jpg" alt="Bencie Woll">
                                                        <h4>Bencie Woll</h4>
													</div>
                                                </div>
                                            </div>
                                        </li>

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    14<sup>40</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/oscar-koller.jpeg" alt="Oscar Koller">
                                                </div>
                                                <h4 class="accordion-title">Invited talk by <b>Oscar Koller</b>: <br><i>Sign Language Recognition - From Dispersed to Comparable Research</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													</p><h4><b>Bio:</b></h4>
                                                    Since January 2018, Oscar Koller is an applied scientist in Microsoft’s 
                                                    Speech and Language group led by Xuedong Huang. From 2011 till 2018, he 
                                                    was a doctoral student researcher in the Human Language Technology &amp; 
                                                    Pattern Recognition Group led by Prof. Ney at RWTH Aachen University, 
                                                    Germany. He followed a dual supervision by Prof. Bowden and his Cognitive
                                                    Vision group at University of Surrey, UK, where he spent 12 months as 
                                                    a visiting researcher. His main research interests include the areas 
                                                    of speech recognition, computer vision, sign language recognition, 
                                                    gesture recognition and lip reading.
                                                <p></p>

                                                <p>
													</p><h4><b>Abstract:</b></h4>
													In this talk we will look into the state of the art in sign language 
													recognition to enable us sketch the requirements for future research that 
													is needed. The talk is meant to be an overview of the field, focusing on 
													the move from dispersed research to the current momentum it has gained. We 
													will look into comparable research studies on the available benchmark data 
													sets. We will analyse the statistics of popular sign language tasks to 
													understand what is needed to continue on the field's accelerated journey to 
													real accessibility. This will also include an investigation in how our 
													research published at TPAMI helps dealing with the specific challenges in 
													sign language recognition.
												<p></p>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/oscar-koller.jpeg" alt="Oscar Koller">
                                                        <h4>Oscar Koller</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>


										<li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>10</sup>
                                                </span>
                                                <h4 class="accordion-title">Coffee Break 1</h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                    
                                                </p>
                                            </div>
                                        </li>


                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>20</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/christian-vogler.jpg" alt="Christian Vogler">
                                                </div>
                                                <h4 class="accordion-title">Invited talk by <b>Christian Vogler</b>: <br><i>Sign Language Technologies: What are We Hoping to Accomplish?</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                    </p><h4><b>Bio</b></h4>
                                                    Dr. Christian Vogler is a professor in the Communication Studies program. 
                                                    He also is the director of the Technology Access Program research group. 
                                                    He leads and co-leads multiple research grants that focus on accessible technology 
                                                    for the deaf and hard of hearing. Topics include video relay services, captioned 
                                                    telephone services, closed captions for TV and streaming video, better consumer 
                                                    control over hearing aids and cochlear implants, next-generation smart home alerting 
                                                    systems, and accessibility of voice interfaces like Amazon Alexa and Google Assistant. 
                                                    He collaborates closely with Dr. Raja Kushlanagar at the IT program, Dr. Patrick Boudreault 
                                                    at Interpreting, and HSLS faculty.

                                                    <br>
                                                    In his role, he also is involved in bringing consumers, industry, and policymakers together 
                                                    on accessibility issues, advocating for a deaf/hard of hearing perspective, as well as developing 
                                                    prototype technologies for improving the accessibility of such systems. Prior to joining TAP in 2011, 
                                                    Dr. Vogler has worked on various research projects related to sign language recognition and facial 
                                                    expression recognition from video at the University of Pennsylvania; the Gallaudet Research Institute; 
                                                    UNICAMP in Campinas, Brazil; and the Institute for Language and Speech Processing in Athens, Greece.

                                                    <br>
                                                    Dr. Vogler passionately believes that deaf and hard of hearing people have only 
                                                    scratched the surface of what is possible with the internet and mobile communication technologies, 
                                                    and that the most exciting technological developments are still to come. He always is on the lookout 
                                                    for students who are interested in communication technologies and want to make a difference in how we use them.
                                                <p></p>
                                                <p>
                                                    </p><h4><b>Abstract</b></h4>
                                                    When we mention sign language recognition technologies to the deaf community, the most common response 
                                                    is a collective groan. In this talk we explain why this is the case. We further provide an analysis of the 
                                                    challenges with the current state of the field, and what can be done to improve matters. 
                                                    Collaboration with the deaf front and center is key, as is identifying realistic applications 
                                                    that people will want to use, based on inclusive principles that respect the community.
                                                <p></p>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/christian-vogler.jpg" alt="Christian Vogler">
                                                        <h4>Christian Vogler</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li> -->

                                        
										<!-- <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>50</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/matt-huenerfauth.jpg" alt="Matt Huenerfauth">
                                                </div>
                                                <h4 class="accordion-title">Invited talk by <b>Matt Huenerfauth</b>: <br><i>Creating Useful Applications with Imperfect, Sign-Language Technologies</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													</p><h4><b>Bio</b></h4>
													Matt Huenerfauth is a Professor at Rochester Institute of Technology (RIT) 
													and director of RIT's iSchool (School of Information). He studies the design 
													of technology to benefit people who are Deaf or Hard of Hearing or who have 
													low written-language literacy, and his team of over 30 research students operates 
													bilingually in English and American Sign Language (ASL). He has secured $5 million 
													USD in external research funding since 2007, including a U.S. National Science 
													Foundation CAREER Award in 2008. He has authored over 90 peer-reviewed scientific 
													journal articles, book chapters, and conference papers, and he is a five-time 
													recipient of the Best Paper Award at the ACM SIGACCESS Conference on Computers 
													and Accessibility (ASSETS), more than any other individual in the conference 
													history. In 2019, he completed a maximum six-year term as editor-in-chief of 
													the ACM Transactions on Accessible Computing (TACCESS) journal. In 2018, RIT 
													awarded him the Trustees Scholarship Award, the university’s highest honor for faculty research.
                                                <p></p>
                                                <p>
													</p><h4><b>Abstract</b></h4>

													Creating sign-language recognition and synthesis technologies is difficult, and 
													state-of-the-art systems are still imperfect.  This limitation presents a challenge 
													for researchers in seeking resources to support dataset creation, user requirements 
													gathering, and other critical infrastructure for the field.  This talk examines how 
													it is possible to create useful applications in the near-term, to motivate research 
													that would have long-term benefit to the field. Examples of funded projects that 
													integrate imperfect sign-language technologies are discussed, including: providing 
													automatic feedback for students learning American Sign Language (ASL) through analysis 
													of videos of their signing, creating search-by-video interfaces for ASL dictionaries, 
													generating understandable ASL animations to improve information access, and providing 
													ASL content in reading-assistance software.  The common thread is that the technologies 
													at the core of each project (i.e. human animation synthesis or recognition of video of 
													human motion) are all imperfect artificial-intelligence systems that occasionally fail 
													in non-human-like ways.  We investigate how to adapt these imperfect technologies for 
													new domains, and we use human-computer interaction research methods to evaluate alternative 
													system designs.  Our goal is to enable users to cope with current limitations of these 
													intelligent technologies so that they benefit from applications that employ them.
												<p></p>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/matt-huenerfauth.jpg" alt="Matt Huenerfauth">
                                                        <h4>Matt Huenerfauth</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    16<sup>20</sup>
                                                </span>
                                                <h4 class="accordion-title"><b>Q&amp;A for Accepted Papers - Session 1</b></h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                </p>
                                                <div style="list-style-type:none">
                                                    <div class="divTable">
                                                        <div class="divTableBody">
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.01.011.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);">  1- Automatic Segmentation of Sign Language into Subtitle-Units </b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Hannah Bull (LIMSI-CNRS), 
                                                                            Michele Gouiffes (LIMSI-CNRS), 
                                                                            Annelies Braffort (LIMSI-CNRS)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.02.012.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 2- Phonologically-meaningful Subunits for Deep Learning-based Sign Language Recognition</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Mark Borg (University of Malta),
                                                                            Kenneth P. Camilleri (University of Malta)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.03.015.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 3- Recognition of affective and grammatical facial expressions: a study for Brazilian sign language</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Emely Pujolli da Silva (University of Campinas),
                                                                            Paula Dornhofer Paro Costa (University of Campinas),
                                                                            Kate Mamhy Oliveira Kumada (Federal University of ABC),
                                                                            José Mario De Martino (University of Campinas),
                                                                            Gabriela Araujo Florentino (Seli Institute)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.04.017.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 4- Real-Time Sign Language Detection using Human Pose Estimation</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Amit Moryossef (Bar-Ilan University, Google), 
                                                                            Ioannis Tsochantaridis (Google), 
                                                                            Roee Aharoni (Google), 
                                                                            Srini Narayanan (Google), 
                                                                            Sarah Ebling (University Of Zurich)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.05.026.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 5- Exploiting 3D Hand Pose Estimation in Deep Learning-Based Sign Language Recognition from RGB Videos</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Maria Parelli (National Technical University of Athens), 
                                                                            Katerina Papadimitriou (University of Thessaly), 
                                                                            Gerasimos Potamianos (University of Thessaly), 
                                                                            Georgios Pavlakos (University of Pennsylvania), 
                                                                            Petros Maragos (National Technical University of Athens)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>                                              
                                            </div>
                                        </li> -->

                                        <!-- <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    16<sup>40</sup>
                                                </span>
                                                <h4 class="accordion-title">Coffee Break 2</h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                    
                                                </p>
                                            </div>
                                        </li>

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    16<sup>50</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/lale-akarun.jpg" alt="Lale Akarun">
                                                </div>
                                                <h4 class="accordion-title">Invited talk by <b>Lale Akarun</b>: <br><i>Turkish Sign Language Recognition at Boğaziçi University</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													</p><h4><b>Bio</b></h4>
                                                    Lale Akarun is a professor of Computer Engineering and the director of the
                                                    Center for Telecommunications and Informatics (http://tetam.boun.edu.tr/en).
                                                    She received the PhD degree in Electrical Engineering from the Polytechnic
                                                    School of Engineering of NYU, in 1992. She has been a faculty member at
                                                    Bogazici University, Istanbul since 1993. She has served as Department
                                                    Head of Computer Engineering (2010-2012) and Vice Rector for Research
                                                    (2012-2016). As Vice Rector, her responsibilities included Sponsored
                                                    Research Projects, Technology Transfer, Incubation Centers and
                                                    Technoparks of the University. Her research areas are in image processing
                                                    and computer vision, and in particular, processing of faces and gestures. She
                                                    has supervised over 50 graduate theses and published more than 200
                                                    scholarly papers in scientific journals and refereed conferences. She has
                                                    conducted research projects in biometrics, face recognition, hand gesture
                                                    recognition, human-computer interaction, and sign language recognition.
                                                <p></p>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/lale-akarun.jpg" alt="Lale Akarun">
                                                        <h4>Lale Akarun</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    17<sup>20</sup>
                                                </span>
                                                <h4 class="accordion-title"><b>Q&amp;A for Accepted Papers - Session 2</b></h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                </p>
                                                <div style="list-style-type:none">
                                                    <div class="divTable">
                                                        <div class="divTableBody">
                                                            <!--<div class="divTableRow">
                                                                <div class="divTableCell"><h5table><b>* Title</b><br><lti>Authors</lti></h5table></div>
                                                            </div>-->
                                                            <!-- <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.06.005.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 6- A Plan for Developing an Auslan Communication Technologies Pipeline</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Jessica Korte (The University of Queensland),
                                                                            Axel Bender (Defense Science and Technology, Australia),
                                                                            Guy Gallasch (Defense Science and Technology, Australia), 
                                                                            Janet Wiles (The University of Queensland),
                                                                            Andrew Back (The University of Queensland)                                  
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.07.010.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 7- A Multi-modal Machine Learning Approach and Toolkit to Automate Recognition of Early Stages of Dementia among British Sign Language Users </b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Xing Liang (University of Greenwich),
                                                                            Anastassia Angelopoulou (University of Westminster),
                                                                            Epaminondas Kapetanios (University of Westminster),
                                                                            Bencie Woll (DCAL, University College of London), 
                                                                            Reda Al-batat (University of Westminster),
                                                                            Tyron Woolfe (DCAL, University College London)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.08.016.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 8- Score-level Multi Cue Fusion for Sign Language Recognition</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Çağrı Gökçe (Bogazici University),
                                                                            Oğulcan Özdemir (Bogazici University),
                                                                            Ahmet Alp Kindiroglu (Bogazici University),
                                                                            Lale Akarun (Bogazici University)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.09.028.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 9- Unsupervised Discovery of Sign Terms by K-Nearest Neighbours Approach</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Korhan Polat (Bogazici University),
                                                                            Murat Saraçlar (Bogazici University)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/full_papers/SLRTP.FP.10.029.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 10- Improving Keyword Search Performance in Sign Language with Hand Shape Features</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Nazif Can Tamer (Bogazici University),
                                                                            Murat Saraçlar (Bogazici University)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div> -->
                                                            <!-- <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.11.007.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 11- Towards Continuous Recognition of Illustrative and Spatial Structures in Sign Language</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Valentin Belissen (LIMSI-CNRS),
                                                                            Annelies Braffort (LIMSI-CNRS), 
                                                                            Michele Gouiffes (LIMSI-CNRS)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.12.009.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 12- Attention is All You Sign: Sign Language Translation with Transformers</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Kayo Yin (École Polytechnique),
                                                                            Jesse Read (Ecole Polytechnique)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.13.014.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 13- How2Sign: A Large-scale Multimodal Dataset for Continuous American Sign Language</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Amanda Duarte (Universitat Politecnica de Catalunya),
                                                                            Shruti Palaskar (Carnegie Mellon University),
                                                                            Deepti Ghadiyaram (Facebook AI),
                                                                            Kenneth De Haan (Gallaudet University),
                                                                            Florian Metze (Carnegie Mellon University),
                                                                            Jordi Torres (Universitat Politecnica de Catalunya),
                                                                            Xavier Giro-i-Nieto (Universitat Politecnica de Catalunya)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.14.018.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 14- Can Everybody Sign Now? Exploring Sign Language Video Generation from 2D Poses</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Lucas Ventura (Universitat Politecnica de Catalunya),
                                                                            Amanda Duarte (Universitat Politecnica de Catalunya),
                                                                            Xavier Giro-i-Nieto (Universitat Politecnica de Catalunya)
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.15.022.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 15- 3D Hands, Face and Body Extraction for Sign Language Recognition</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Agelos Kratimenos (National Technical University of Athens),
                                                                            Georgios Pavlakos (University of Pennsylvania),
                                                                            Petros Maragos (National Technical University of Athens)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.16.023.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 16- Effect of Ranking and Precision of Results on Users' Satisfaction with Search-by-Video Sign-Language Dictionaries</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Saad Hassan (Rochester Institute of Technology),
                                                                            Oliver Alonzo (Rochester Institute of Technology),
                                                                            Abraham Glasser (Rochester Institute of Technology),
                                                                            Matt Huenerfauth (Rochester Institute of Technology)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.17.025.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 17- Fingerspelling recognition in the wild with iterative visual attention</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Bowen Shi (Toyota Technological Institute at Chicago), 
                                                                            Aurora Martinez Del Rio (University of Chicago),
                                                                            Jonathan Keane (University of Chicago),
                                                                            Diane Brentari (University of Chicago),
                                                                            Greg Shakhnarovich (Toyota Technological Institute at Chicago),
                                                                            Karen Livescu (Toyota Technological Institute at Chicago)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                            <div class="divTableRow">
                                                                <div class="divTableCell">
                                                                    <h5table>
                                                                        <a href="https://slrtp.com/papers/extended_abstracts/SLRTP.EA.18.027.paper.pdf" target="_blank">
                                                                            <i class="fa fa-file-pdf-o" style="margin-right: 0.1em;font-size:18px;color:red"></i>
                                                                            <b style="line-height: 2rem; color: rgb(100, 100, 100);"> 18- On How Deaf and Hard of Hearing Users Might Use Sign Language Conversational User Interfaces</b>
                                                                        </a>
                                                                        <br>
                                                                        <lti style="font-size:14px;">
                                                                            Abraham Glasser (Rochester Institute of Technology), 
                                                                            Vaishnavi Mande (Rochester Institute of Technology), 
                                                                            Matt Huenerfauth (Rochester Institute of Technology)                                    
                                                                        </lti>
                                                                    </h5table>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>                                              
                                            </div> -->
                                        <!-- </li> --> 

                                        <!-- <li>
											<a class="accordion-heading">
												<span class="schedule-time accent">
													17<sup>55</sup>
												</span>
												<h4 class="accordion-title">Closing Remarks</h4>
											</a>
                                            <div class="accordion-body" style="display: none;">
												<p>
												</p>
											</div>
										</li> -->
									</ul>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>
			<!--==========-->

			<!--==========-->

            

			<section id="organizers" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Organizers</b></h2>
						</div>
					</div>
				</div>
    
				<div class="row">
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/liliane-momeni.jpg" alt="Liliane Momeni">
							<div class="speaker-info">
								<h3>Liliane<br> <b>Momeni</b></h3>
								<p>PhD Student<br> <i>University of Oxford</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.robots.ox.ac.uk/~liliane/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/gul-varol.jpg" alt="Gul Varol">
							<div class="speaker-info">
								<h3>Gül<br> <b>Varol</b></h3>
								<p>Assistant Professor<br><i>École des Ponts ParisTech</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.robots.ox.ac.uk/~gul/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/samuel-albanie.jpg" alt="Samuel Albanie">
							<div class="speaker-info">
								<h3>Samuel<br> <b>Albanie</b></h3>
								<p>Assistant Professor<br><i>University of Cambridge</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.robots.ox.ac.uk/~albanie/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/hannah-bull.jpg" alt="Hannah Bull">
							<div class="speaker-info">
								<h3>Hannah<br> <b>Bull</b></h3>
								<p>PhD Student<br> <i>University of Paris-Saclay</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://hannahbull.github.io/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
				<div class="row">
				</div>
					<div class="col-sm-6 col-md-1-5 ">
						
					</div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/neil-fox.jpg" alt="Cihan Camgoz">
							<div class="speaker-info">
								<h3>Neil<br> <b>Fox</b></h3>
								<p>Research Assistant<br> <i>DCAL</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.ucl.ac.uk/dcal/people/research-staff/neil-fox" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
                        <div class="speaker">
                            <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/ben-saunders.jpg" alt="Ben Saunders">
                            <div class="speaker-info">
                                <h3>Ben<br> <b>Saunders</b></h3>
                                <p>PhD Student<br> <i>University of Surrey</i></p>
                            </div>
                            <ul class="speaker-contacts">
                                <li><a target="_blank" href="https://bensaunders27.github.io/" class="fa fa-home"></a></li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/cihan-camgoz.jpg" alt="Cihan Camgoz">
							<div class="speaker-info">
								<h3>Necati Cihan<br> <b>Camgöz</b></h3>
								<p>Research Fellow<br> <i>University of Surrey</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.cihancamgoz.com/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                
                    <div class="row">
                    </div>
                        <div class="col-sm-6 col-md-1-5 ">
                            
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/richard-bowden.jpg" alt="Richard Bowden">
                                <div class="speaker-info">
                                    <h3>Richard<br> <b>Bowden</b></h3>
                                    <p>Professor<br> <i>University of Surrey</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.surrey.ac.uk/people/richard-bowden" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/andrew-zisserman.jpg" alt="Andrew Zisserman">
                                <div class="speaker-info">
                                    <h3>Andrew<br> <b>Zisserman</b></h3>
                                    <p>Professor<br> <i>University of Oxford</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.robots.ox.ac.uk/~az/" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/bencie-woll.jpg" alt="Bencie Woll">
                                <div class="speaker-info">
                                    <h3>Bencie<br> <b>Woll</b></h3>
                                    <p>Professor<br> <i>DCAL</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.ucl.ac.uk/dcal/people/core-team/professor-bencie-woll" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
				</div>
                
            <!--===============================-->
            <!--== Thanks =====================-->
            <!--===============================-->
			</section>
			<!--==========-->

            <!--===============================-->
            <!--== Sponsors ===================-->
            <!--===============================-->
			

			<!--===============================-->
			<!--== Footer =====================-->
			<!--===============================-->
			<footer id="footer" class="footer">
				<div class="row">
					<div class="col-sm-8">

					</div>
					<div class="col-sm-4 text-right">
						<div class="copyrights">All Rights Reserved. © 2022 </div>
					</div>
				</div>
			</footer>
			<!--==========-->

		</div>

		<!--== Javascript Files ==-->
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery-2.1.0.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/bootstrap.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/SmoothScroll.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/typed.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery.nav.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery.stellar.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery.flexslider-min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery.placeholder.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/jquery.accordion.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/owl.carousel.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/fancySelect.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/wow.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/gmap3.min.js"></script>
		<script src="./SLRTP 2020_ Sign Language Recognition, Translation and Production Workshop_files/main.min.js"></script>
	

</body></html>
