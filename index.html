<!DOCTYPE html>
<!-- saved from url=(0018)https://slrtp.com/ -->
<html lang="en"><head>
		<title>SLRTP 2022: Sign Language Recognition, Translation and Production Workshop</title>
		  
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        
		<!--== CSS Files ==-->
		<link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
		<link href="css/style.min.css" rel="stylesheet" media="screen">
		<link href="css/animate.min.css" rel="stylesheet" media="screen">
		<link href="css/font-awesome.css" rel="stylesheet" media="screen">
		<link href="css/flexslider.css" rel="stylesheet" media="screen">
		<link href="css/fancySelect.css" rel="stylesheet" media="screen">
		<link href="css/owl.carousel.css" rel="stylesheet" media="screen">
		<link href="css/responsive.css" rel="stylesheet" media="screen">
	

		<!--== Google Fonts ==-->
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,700,400italic' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700' rel='stylesheet' type='text/css'>
	
		<meta name="keywords" content="ECCV, Sign Language Recognition, Sign Language Translation, Sign Language Production, Workshop, ECCV Workshop">
		<meta name="description" content="ECCV 2022 Workshop on Sign Language Recognition, Translation and Production.">
		<meta name="author" content="Gul Varol">
		<meta name="viewport" content="width=device-width, initial-scale=0.75">
		<meta http-equiv="Cache-control" content="public" max-age="86400">
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:creator" content="@LiliMomeni">
		<meta name="twitter:title" content="SLRTP workshop ECCV 2022" />
		<meta name="twitter:description" content="Sign Language Recognition, Translation & Production" />
		<meta name="twitter:image" content="https://raw.githubusercontent.com/slrtp-2022/slrtp-2022.github.io/main/images/logo/slrtp_twitter_card.png" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://slrtp-2022.github.io/" />
		<meta property="og:title" content="SLRTP workshop ECCV 2022" />
		<meta property="og:description" content="Sign Language Recognition, Translation & Production" />
		<meta property="og:image" content="https://raw.githubusercontent.com/slrtp-2022/slrtp-2022.github.io/main/images/logo/slrtp_twitter_card.png" />
	<!--<script type="text/javascript" charset="UTF-8" src="js/common.js"></script><script type="text/javascript" charset="UTF-8" src="js/util.js">
		
	</script>-->
	</head>
	<body>
		<div id="home"></div>
		<header id="header" class="header" data-stellar-ratio="0.5" style="transform: translate3d(0px, 649.5px, 0px);">

			<!--== Preloader ==-->
			<div id="preloader" class="ready"><div class="preloader"></div></div>

			<!--== Caption ==-->
            
			<div class="header-caption" data-stellar-ratio="2" style="transform: translate3d(0px, -1299px, 0px);">
				<div class="container">
					<div class="box">
                        <p style="color:white;">In conjunction with ECCV 2022</p>
                        <!-- <h2w>In conjunction with ECCV 2022<br></h2w>
						<span class="typed">virtually</span><span class="typed-cursor">|</span> -->
					</div>
				</div>
			</div>

			<!--== Header Background ==-->
			<div id="header-background" class="header-background">
				<ul class="slides">
                    <li class="flex-active-slide" style="width: 100%; float: left; margin-right: -100%; position: relative; display: block; z-index: 2; opacity: 1;"><img src="images/logo/slrtp_black.png" alt="ECCV Workshop 2020 - SLRTP" draggable="false" style="margin-left: -718.5px; margin-top: -539px;"></li>
				</ul>
			</div>

		</header>

		<div id="navigation-wrap" class="navigation-wrap sticky">
			<div id="navigation" class="navigation">
				<div class="container">
					<nav class="navbar navbar-custom" role="navigation">

						<div class="navbar-header">
							<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#menu">
								<span class="sr-only">Toggle navigation</span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
						</div>

						<!--== Site Menu ==-->
						<div class="collapse navbar-collapse" id="menu">
							<ul class="nav navbar-nav">
								<li class=""><a href="https://slrtp.com/#home">Home</a></li>
                                <li class=""><a href="https://slrtp.com/#challenge">Challenge</a></li>
                                <li class=""><a href="https://slrtp.com/#dates">Dates</a></li>
                                <li class=""><a href="https://slrtp.com/#keynotes">Keynotes</a></li>
                                <li class=""><a href="https://slrtp.com/#schedule">Schedule</a></li>
                                <li class=""><a href="https://slrtp.com/#organizers">Organizers</a></li>
                                <li class=""><a href="https://slrtp.com/#news">News</a></li>
							</ul>
						</div>

					</nav>
				</div>
			</div>
		</div>
        
		<div class="container content">     

		<!--===============================-->
			<!--== About ======================-->
			<!--===============================-->

			<section id="about">
				<div class="row">
					<div class="col-sm-12 col-md-12">
						<p>Sign languages are spatial-temporal languages and constitute a key form of communication for Deaf communities. Recent progress in fine-grained gesture and
                            action classification, machine translation and image captioning, point to the
                            possibility of automatic sign language understanding becoming a reality. The
                            study of isolated sign recognition has a rich history in the computer vision community stretching back over thirty years. Thanks to the recent availability of
                            larger datasets, researchers are now focusing on continuous sign language recognition, sentence alignment to continuous signing and sign language translation.
                            Advances in generative networks are also enabling progress on sign language
                            production, where written language is converted into sign language video.
                            </p>

                        <p> The "Sign Language Recognition, Translation & Production" (SLRTP) Workshop brings together researchers working on different aspects of vision-based sign language research (including body posture, hands and face) and sign language linguists. The focus of this workshop is to broaden participation in sign language research from the computer vision community. We hope to identify
                            important future research directions, and to cultivate collaborations.
                            The workshop will consist of invited talks and also a challenge with three
                            tracks: individual sign recognition; English sentence to sign sequence alignment; and sign spotting.</p>


                        <p><b>Workshop languages/accessibility: </b>    
                            The languages of this workshop are English, British Sign Language (BSL), and International Sign (IS). Interpretation between BSL/English and IS/English will be provided, as will English subtitles, for all pre-recorded and live Q&A sessions. If you have questions about this, please contact us. 
                        </p>   
					</div>
				</div>
			</section>

            <section id="challenge">
                <div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Challenge</b></h2>
						</div>
					</div>
					<center><p>See <a href="https://docs.google.com/document/d/e/2PACX-1vR3tN1OD0g0D_4rtYB5wnCWsHB1fpA2x-_DipoPzk08DLEHeJMPYKtHVHfTLX63mwQkRa4Q0szW3wgX/pub">ECCV22_SLRTP_Challenge.pdf</a> for challenge descriptions, instructions, terms and conditions.</p></center>
					<p style="color:red">Note: Participants are encouraged to request access to the dataset(s) used for the challenge as soon as possible, since it may take several days to obtain permission to download.</p>
                    <p>The challenge has <u>three</u> tracks. 
                        The first track is (1) <b>sign recognition</b> from
                        co-articulated signing for a large number of classes – the task is to classify individual signs in 
                        continuous signing sequences given their approximate temporal extent. This
                        should encourage discussion on how to best (i) exploit complementary signals
                        across different modalities and articulators, (ii) model temporal information,
                        (iii) account for long-tailed distributions.</p>
                    
                    <p>The second track is for (2) <b>alignment</b>
                        of spoken language sentences to continuous signing – the task of determining
                        the temporal extent of a signing sequence, given its English translation. This
                        is a key step for automatically constructing a parallel corpus for sign language
                        translation. This should encourage discussion on how to best model video and
                        text jointly.</p>
                    
                    <p>The final track is (3) <b>sign spotting</b> : here the task is to identify whether and 
                        when a sign is performed in a given window of continuous signing. Sign spotting has a
                         range of applications including: indexing of signing content to enable efficient search 
                         and “intelligent fast-forward” to topics of interest, automatic sign language dataset 
                         construction and “wake-word” recognition for signers.</p>
                    
                    <p>Teams that submit their results to the challenges will also be required to submit a description of their systems. At the workshop, we will invite presentations
                        from the challenge winners.</p>
                    
                    <div class="row">
                        <div class="col-sm-12">
                            <div class="content-tabs">
                                <div class="tab-content">
                                    <div class="tab-pane fade in active" id="tab1">
                                        <ul class="accordion">
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 1
                                                    </span>
                                                    <p class="accordion-title"> <b>Sign recognition</b> from co-articulated signing on BOBSL
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        <a href="https://codalab.lisn.upsaclay.fr/competitions/6724">Link to Codalab page: https://codalab.lisn.upsaclay.fr/competitions/6724</a>
                                                    <p></p>
                                                </div>
                                            </li>
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 2
                                                    </span>
                                                    <p class="accordion-title"> <b>Alignment</b> of spoken language sentences to continuous signing on BOBSL
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        <a href="https://codalab.lisn.upsaclay.fr/competitions/6790">Link to Codalab page: https://codalab.lisn.upsaclay.fr/competitions/6790</a>
                                                    <p></p>
                                                </div>
                                            </li>
                                            <li>
                                                <a class="accordion-heading">
                                                    <span class="schedule-time accent">
                                                        Track 3
                                                    </span>
                                                    <p class="accordion-title"> <b>Sign spotting </b> in continuous co-articulated signing on BSL Corpus
                                                    </p>
                                                </a>
                                                <div class="accordion-body" style="display: none;">
                                                    <p>
                                                        <a href="https://codalab.lisn.upsaclay.fr/competitions/6803">Link to Codalab page: https://codalab.lisn.upsaclay.fr/competitions/6803</a>
                                                    <p></p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

				</div>
                
            </section>
            

        <section id="dates">
                <div class="row">
                    <div class="col-sm-12 col-md-2">
                        <div class="section-header text-left">
                            <h2><b>Dates</b></h2>
                        </div>
                    </div>
                    <div class="col-sm-12 col-md-9">
                        <ul style="list-style-type:none">
                            <div class="divTable">
                            <div class="divTableBody">
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Challenge development phase begins: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>August 5, 2022</b></lti> </h4table></div>
                            </div>
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Challenge test phase begins: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>September 12, 2022</b></lti> </h4table></div>
                            </div>
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Challenge close: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>October 7, 2022</b></lti> </h4table></div>
							</div>
							<div class="divTableRow">
								<div class="divTableCell"><h4table>Winners announced: </h4table></div>
								<div class="divTableCell"><h4table><lti><b>October 10, 2022</b></lti> </h4table></div>
							</div>
							<div class="divTableRow">
								<div class="divTableCell"><h4table>Winners 10-min pre-recorded videos due: </h4table></div>
								<div class="divTableCell"><h4table><lti><b>October 17, 2022</b></lti> </h4table></div>
							</div>
                            <div class="divTableRow">
                            	<div class="divTableCell"><h4table>Workshop date: </h4table></div>
                            	<div class="divTableCell"><h4table><lti><b>October 24, 2022</b></lti> </h4table></div>
                            </div>
                            </div>
						</ul>
                        <div class="row">
                </div>
            </section>
			<!--===============================-->
			<!--== Keynotes ===================-->
			<!--===============================-->
			<section id="keynotes" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Keynotes</b></h2>
						</div>
					</div>
				</div>

                <div class="row">
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/speakers/melissa-malzkuhn.jpg" alt="Melissa Malzkuhn">
							<div class="speaker-info">
								<h3>Melissa<br> <b>Malzkuhn</b></h3>
								<p>Founder<br> <i>Motion Light Lab</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://mezmalz.com/about" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/speakers/mark-wheatley.jpg" alt="Mark Wheatley">
							<div class="speaker-info">
								<h3>Mark<br> <b>Wheatley</b></h3>
								<p>Executive Director<br><i>European Union of the Deaf</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.edf-feph.org/profile/markwheatley/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/speakers/sarah-ebling.jpg" alt="Sarah Ebling">
							<div class="speaker-info">
								<h3>Sarah<br> <b>Ebling</b></h3>
								<p>Senior researcher<br><i>University of Zurich</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.cl.uzh.ch/de/people/team/compling/ebling.html" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
	
			                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/speakers/adam-munder.jpeg" alt="Adam Munder">
							<div class="speaker-info">
								<h3>Adam<br> <b>Munder</b></h3>
								<p>Founder of <br><i>Omnibridge</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://omnibridge.ai/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
				<div class="row">
				</div>

			</section>
			<!--==========-->

			<!--===============================-->
			<!--== Schedule ===================-->
            <!--===============================-->
            
			<section id="schedule" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-left">
							<h2>Tentative <b>Schedule</b></h2>
                            <p>Date: <b>Monday 24th October</b><p>
                            <p>Time:  <b>14:00-18:00</b> GMT+3 (Israel Time)</p> 
                            <p> The workshop is fully virtual, <i class="fa fa-video-camera"></i> denotes pre-recorded videos and <i class="fa fa-microphone"></i> denotes live interaction.
                            </p>
                            <p>
                            	The access to the virtual platform will be allowed for ECCV'22 attendees who are <a href="https://eccv2022.ecva.net/attend/">registered with a workshop pass</a>.
                            </p>        
						</div>
					</div>
				</div>
				<div class="row">
					<div class="col-sm-12">
						<div class="content-tabs">
							<div class="tab-content">
								<div class="tab-pane fade in active" id="tab1">
									<ul class="accordion">

										<li>
											<a class="accordion-heading">
												<span class="schedule-time accent">
													14<sup>00</sup>
												</span>
												<h4 class="accordion-title">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<i class="fa fa-microphone"></i> &nbsp Opening Remarks</h4>
											</a>
                                            <div class="accordion-body" style="display: none;">
												<p>
												</p>
											</div>
										</li> 


                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    14<sup>10</sup>
                                                </span>
                                                <h4 class="accordion-title">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<i class="fa fa-microphone"></i> &nbsp <b>Challenges Discussion</b> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
												<iframe class='fitvidsignore' width='1024px' height='576px' src='https://www.youtube.com/embed/BdiShhtBlNk' frameborder='0' allow='accelerometer; encrypted-media; gyroscope; picture-in-picture' allowfullscreen='allowfullscreen'>&nbsp;</iframe>
                                            </div>
                                        </li>

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    14<sup>35</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="images/speakers/sarah-ebling.jpg" alt="Sarah Ebling">
                                                </div>
                                                <h4 class="accordion-title"><i class="fa fa-video-camera"></i> + <i class="fa fa-microphone"></i> &nbsp Invited talk by <b>Sarah Ebling</b>: <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <i>Developing Sign Language Technologies for the Users: Insights from a NLP Perspective</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                    <h4><b>Abstract</b></h4>
                                                    In this talk, I will discuss the challenges involved in automatic sign language processing (sign language translation, recognition, and synthesis) specifically from a natural language processing (NLP) perspective. I will highlight the importance of including the end users in the research and development cycle and talk about aspects to consider when collecting and preparing data to train deep learning models. The talk ends with an exemplary presentation of different research contributions of our group.
                                                    <h4><b>Bio</b></h4>
                                                    Dr. Sarah Ebling is a senior researcher at the University of Zurich, where she leads the "Language Technology for Accessibility" group, and the head of the "Accessible Communication" group at Zurich University of Applied Sciences. Her research focuses on natural language processing for persons with disabilities and special educational needs, specifically, sign language technology and automatic text simplification. She is involved in various international (EU H2020) and national (Swiss National Science Foundation Sinergia) projects and is PI to a large-scale Swiss innovation project entitled „Inclusive Information and Communication Technologies“ (2022-2026; https://www.iict.uzh.ch/).
                                                </p>
												<iframe class='fitvidsignore' width='1024px' height='576px' src='https://www.youtube.com/embed/pY_GgRivaPw' frameborder='0' allow='accelerometer; encrypted-media; gyroscope; picture-in-picture' allowfullscreen='allowfullscreen'>&nbsp;</iframe>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="images/speakers/sarah-ebling.jpg" alt="Sarah Ebling ">
                                                        <h4>Sarah Ebling</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>

                                        

                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>05</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="images/speakers/mark-wheatley.jpg" alt="Mark Wheatley">
                                                </div>
                                                <h4 class="accordion-title"><i class="fa fa-video-camera"></i> + <i class="fa fa-microphone"></i> &nbsp Invited talk by <b>Mark Wheatley</b>: <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <i>Co-creation in machine translation projects: the role of deaf organisations</i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													<h4><b>Abstract:</b></h4>
                                                	In this presentation, I reflect on the involvement of the European Union of the Deaf (EUD) in two signed-spoken language machine translation projects that are currently underway: EASIER and SignON. Both projects are funded by the EU Horizon 2020 program, and aim to create flexible mobile applications that can provide machine translation between various European signed and spoken languages. These projects have connected technology experts with sign language academics and deaf-led organisations to ensure their projects are well-fit to deaf communities. I describe the role of the EUD in the projects, how deaf community perspectives are included at different stages of project development, and the insights that have emerged from our involvement. Particularly, I discuss how user research has been critical in establishing use-cases that are acceptable to deaf communities. 
													<h4><b>Bio:</b></h4>
                                                    Mark Wheatley has operated as the Executive Director of the European Union of the Deaf (EUD) since 2007. Under his leadership, EUD has grown to be a more visible organisation, both in terms of its external (social) media coverage and its internal member communication. He is co-author of the EUD book “Sign Language Legislation in the European Union”. He has been a member of the World Federation of the Deaf (WFD) Expert Group on Human Rights. Furthermore, he was involved as an expert in the World Health Organisation and World Bank World Report on Disability to ensure that sign language users were adequately included both in terms of terminology and accuracy of information. He also contributed to various academic publications on the topic of sign language and technological development as an enabler of deaf rights.
                                                </p>
												<iframe class='fitvidsignore' width='1024px' height='576px' src='https://www.youtube.com/embed/LagJmVJOmQg' frameborder='0' allow='accelerometer; encrypted-media; gyroscope; picture-in-picture' allowfullscreen='allowfullscreen'>&nbsp;</iframe>

                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="images/speakers/mark-wheatley.jpg" alt="Mark Wheatley">
                                                        <h4>Mark Wheatley</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>


										<li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>30</sup>
                                                </span>
                                                <h4 class="accordion-title">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Comments on Sign Language Data by <b>Bencie Woll</b> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                </p>
                                            </div>
                                        </li>
										<li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>35</sup>
                                                </span>
                                                <h4 class="accordion-title">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Coffee Break </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                </p>
                                            </div>
                                        </li>


                


                                        
                            

								                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    15<sup>50</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="images/speakers/melissa-malzkuhn.jpg" alt="Melissa Malzkuhn">
                                                </div>
                                                <p class="accordion-title"><i class="fa fa-video-camera"></i> + <i class="fa fa-microphone"></i> &nbsp Invited talk by  <b>Melissa Malzkuhn</b>: <br> 
                                                    &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <i>Signing Avatars: Fluency, Comprehension, Acceptance</i>
                                                </p>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													<h4><b>Abstract</b></h4>
													In this talk, I will discuss how my lab, Motion Light Lab, has tackled on the goal of creating fluency in signing avatars. How fluency is related to comprehension, and how that will impact the uses of avatars, and possible applications. How will it be for the users, in particular Deaf children, navigating through this? I will also discuss the overview of the field of signing avatars, especially how sign language is constructed and represented, with some challenges posed by specific technologies.

													<h4><b>Bio</b></h4>
													Melissa Malzkuhn is an activist, academic, artist, and digital strategist with a love for language play, interactive experiences, and community-based change. Melissa believes that access to language is a human right, and that the obstacles that deprive Deaf children of the chance to learn ASL are structural, societal, and systemic. Her goal is to remove these obstacles, and she has led innovative initiatives that help Deaf children access language at many levels of the system that creates them. <br>
 
													She founded and leads creative research and development at Motion Light Lab, at a Gallaudet University research center. The Lab uses creative literature and digital technology techniques to create immersive learning experiences- from storybook apps that have been translated into over 20 international languages to motion-capture projects that build signing avatars- all of which expand the 3D technology landscape for deaf children, visual learners, and more. <br>
 
													Melissa is a co-founder of CREST Network, focusing on equity and inclusion of deaf people in sign language technology. Her production company Ink & Salt developed an app to teach American Sign Language, The ASL App, which has been downloaded over 2 million times. Third-generation Deaf, she has organized deaf youth and worked with international deaf youth programs, fostering leadership and self-representation. Now, she collaborates with teams in different countries to support literacy development for deaf children through sign language resources. Melissa led the campaign, “Hu:  - To Sign Is Human”, a call for equal access to sign language as a human right, through screen-printed apparel that advocates for language access for all Deaf children.<br>
 
													Her work has been recognized nationally and internationally. She is an Obama Fellow, inaugural class 2018, and has been recognized as a leading social entrepreneur by Ashoka, in 2021. She resides in Maryland with her family. <br>
 
													Socials / Website: @mezmalz on Twitter, www.mezmalz.com, www.motionlightlab.com
												</p>
												<iframe class='fitvidsignore' width='1024px' height='576px' src='https://www.youtube.com/embed/WwMdUVBx61w' frameborder='0' allow='accelerometer; encrypted-media; gyroscope; picture-in-picture' allowfullscreen='allowfullscreen'>&nbsp;</iframe>
                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="images/speakers/melissa-malzkuhn.jpg" alt="Melissa Malzkuhn">
                                                        <h4>Melissa Malzkuhn</h4>
													</div>
                                                </div>
                                            </div>
                                        </li>

										
                                        <li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    16<sup>20</sup>
                                                </span>
                                                <div class="schedule-speaker">
                                                    <img src="./images/speakers/adam-munder.jpeg" alt="Adam Munder">
                                                </div>
                                                <h4 class="accordion-title"><i class="fa fa-video-camera"></i> + <i class="fa fa-microphone"></i> &nbsp Invited talk by <b>Adam Munder</b>: <br>Enabling Inclusive Communication Between Deaf and Hearing with OmniBridge AI Translation <i></i> </h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
													<h4><b>Abstract:</b></h4>
                                                	I will share my journey as a Deaf person navigating my life through the hearing world and
how in 2020, I built a new startup team, OmniBridge, backed by Intel. Today I lead an incredible
team of engineers, annotators, linguists, and marketing experts.  Our dream is to
use technology for good. We have both hearing and deaf people working together toward a
common goal – creating a more inclusive world with easy communication between hearing and
Deaf people.  How do we make these two different languages be understood in the same
conversation?  I will share my stories, struggles, experience, and challenges with you from my
childhood up to the hearing corporate world, and the beautiful world of Deaf Culture. These
experiences have inspired me to make a difference. Our solution is a sign language AI
translation between Deaf and hearing people. Two languages, spoken and signed, in one easy
conversation. Let’s make our world an inclusive place! Together we can truly create a new
world.
													<h4><b>Bio:</b></h4>
                                                    Adam Munder is Deaf, and his primary communication is through sign language. He has worked
at Intel in many engineering roles since 2011. Prior to Intel, he received a National Science
Foundation Scholarship and a variety of internships and work experiences. He has studied
applied robotics, mechanical engineering, manufacturing engineering, physics, nanoscale
device, nano/micro-fabrication, and systems engineering. In the last seven years, he has shifted
to the computer science field, especially deep learning and machine learning. Based on his
experience of climbing the ladder in the corporate world with few designated interpreters, he is
very enthusiastic about creating a barrier-free world for Deaf/HoH people to communicate with
hearing people anywhere at any time inside or outside of the corporate world. Coming from an
all-engineering background, he will bring a new technology focus to innovation. He is now a
cofounder and General Manager of OmniBridge, an Intel Venture.
                                                </p>

												<iframe class='fitvidsignore' width='1024px' height='576px' src='https://www.youtube.com/embed/HKjNkWhZjxE' frameborder='0' allow='accelerometer; encrypted-media; gyroscope; picture-in-picture' allowfullscreen='allowfullscreen'>&nbsp;</iframe>

                                                <div class="schedule-speaker-list">
                                                    <b>Presenters:</b>
                                                    <div class="schedule-speaker">
                                                        <img src="./images/speakers/adam-munder.jpeg" alt="Adam Munder">
                                                        <h4>Adam Munder</h4>
                                                    </div>
                                                </div>
                                            </div>
                                        </li>


									

										<li>
                                            <a class="accordion-heading">
                                                <span class="schedule-time accent">
                                                    16<sup>50</sup>
                                                </span>
                                                <h4 class="accordion-title">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <i class="fa fa-microphone"></i> &nbsp Closing Remarks</h4>
                                            </a>
                                            <div class="accordion-body" style="display: none;">
                                                <p>
                                                </p>
                                            </div>
                                        </li>

									</ul>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>
			<!--==========-->

			<!--==========-->

            

			<section id="organizers" class="wow bounceInUp animated" data-wow-duration="0.8s" data-wow-delay="0.1s" style="visibility: visible; animation-duration: 0.8s; animation-delay: 0.1s; animation-name: bounceInUp;">
				<div class="row">
					<div class="col-sm-12">
						<div class="section-header text-center">
							<h2><b>Organizers</b></h2>
						</div>
					</div>
				</div>
    
				<div class="row">
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/liliane-momeni.jpg" alt="Liliane Momeni">
							<div class="speaker-info">
								<h3>Liliane<br> <b>Momeni</b></h3>
								<p>PhD Student<br> <i>University of Oxford</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.robots.ox.ac.uk/~liliane/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/gul-varol.jpg" alt="Gul Varol">
							<div class="speaker-info">
								<h3>Gül<br> <b>Varol</b></h3>
								<p>Assistant Professor<br><i>École des Ponts ParisTech</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="http://imagine.enpc.fr/~varolg/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/samuel-albanie.jpg" alt="Samuel Albanie">
							<div class="speaker-info">
								<h3>Samuel<br> <b>Albanie</b></h3>
								<p>Assistant Professor<br><i>University of Cambridge</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://samuelalbanie.com/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
					<div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/hannah-bull.jpg" alt="Hannah Bull">
							<div class="speaker-info">
								<h3>Hannah<br> <b>Bull</b></h3>
								<p>PhD Student<br> <i>University of Paris-Saclay</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://hannahbull.github.io/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
				<div class="row">
				</div>

		    <div class="col-sm-6 col-md-3 ">
                        <div class="speaker">
                            <img src="images/organizers/prajwal-kr.jpg" alt="Prajwal KR">
                            <div class="speaker-info">
                                <h3>Prajwal<br> <b>KR</b></h3>
                                <p>PhD Student<br> <i>University of Oxford</i></p>
                            </div>
                            <ul class="speaker-contacts">
                                <li><a target="_blank" href="https://github.com/prajwalkr" class="fa fa-home"></a></li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/neil-fox.jpg" alt="Cihan Camgoz">
							<div class="speaker-info">
								<h3>Neil<br> <b>Fox</b></h3>
								<p>Research Assistant<br> <i>DCAL</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.ucl.ac.uk/dcal/people/research-staff/neil-fox" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                    <div class="col-sm-6 col-md-3 ">
                        <div class="speaker">
                            <img src="images/organizers/ben-saunders.jpg" alt="Ben Saunders">
                            <div class="speaker-info">
                                <h3>Ben<br> <b>Saunders</b></h3>
                                <p>PhD Student<br> <i>University of Surrey</i></p>
                            </div>
                            <ul class="speaker-contacts">
                                <li><a target="_blank" href="https://bensaunders27.github.io/" class="fa fa-home"></a></li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-sm-6 col-md-3 ">
						<div class="speaker">
							<img src="images/organizers/cihan-camgoz.jpg" alt="Cihan Camgoz">
							<div class="speaker-info">
								<h3>Necati Cihan<br> <b>Camgöz</b></h3>
								<p>Research Fellow<br> <i>University of Surrey</i></p>
							</div>
							<ul class="speaker-contacts">
								<li><a target="_blank" href="https://www.cihancamgoz.com/" class="fa fa-home"></a></li>
							</ul>
						</div>
					</div>
                
                    <div class="row">
                    </div>
                        <div class="col-sm-6 col-md-1-5 ">
                            
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="images/organizers/richard-bowden.jpg" alt="Richard Bowden">
                                <div class="speaker-info">
                                    <h3>Richard<br> <b>Bowden</b></h3>
                                    <p>Professor<br> <i>University of Surrey</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.surrey.ac.uk/people/richard-bowden" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="images/organizers/andrew-zisserman.jpg" alt="Andrew Zisserman">
                                <div class="speaker-info">
                                    <h3>Andrew<br> <b>Zisserman</b></h3>
                                    <p>Professor<br> <i>University of Oxford</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.robots.ox.ac.uk/~az/" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-sm-6 col-md-3 ">
                            <div class="speaker">
                                <img src="images/organizers/bencie-woll.jpg" alt="Bencie Woll">
                                <div class="speaker-info">
                                    <h3>Bencie<br> <b>Woll</b></h3>
                                    <p>Professor<br> <i>DCAL</i></p>
                                </div>
                                <ul class="speaker-contacts">
                                    <li><a target="_blank" href="https://www.ucl.ac.uk/dcal/people/core-team/professor-bencie-woll" class="fa fa-home"></a></li>
                                </ul>
                            </div>
                        </div>
				</div>
                
            <!--===============================-->
            <!--== Thanks =====================-->
            <!--===============================-->
			</section>
			<!--==========-->

            <!--===============================-->
            <!--== Sponsors ===================-->
            <!--===============================-->
			



			<!--===============================-->
			<!--== News =======================-->
			<!--===============================-->
			
			<section id="news" class="wow bounceInUp" data-wow-duration="0.8s" data-wow-delay="0.1s">
				<div class="row">
					<div class="col-md-12">
						<div class="section-header text-left">
							<h2>Latest <b>news</b></h2>
							<!--<p>Follow the recent hapennings here.</p>-->
						</div>
					</div>
				</div>
				<div class="row">
					<div class="col-md-12">
						<ul class="news-list">
                                                        <li>
                                <span class="news-date">Aug 5</span>
                                <h4>Challenges begin.</h4>
                            </li>

							<li>
                                <span class="news-date">Aug 2</span>
                                <h4>The tentative schedule is announced. More updates coming soon.</h4>
                            </li>

							<li>
                                <span class="news-date">April 7</span>
                                <h4>Workshop website is up! SLRTP'22 will be held as a virtual event in conjunction with <a href="https://eccv2022.ecva.net/">ECCV'22</a> as part of the <a href="https://signlanguageworkshop.github.io/">Sign Language Understanding Workshop</a>. See the previous SLRTP'20 edition at <a href="https://www.slrtp.com/">www.slrtp.com</a>.</h4>
                            </li>
						</ul>
					</div>
				</div>
			</section>

			<!--===============================-->
			<!--== Footer =====================-->
			<!--===============================-->
			<footer id="footer" class="footer">
				<div class="row">
					<div class="col-sm-8">

					</div>
					<div class="col-sm-4 text-right">
						<div class="copyrights">All Rights Reserved. © 2022 </div>
					</div>
				</div>
			</footer>
			<!--==========-->

		</div>

		<!--== Javascript Files ==-->		
		<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyC_2muaLDbTKdh_ou9fkj8VjaWrFNgVBt0"></script>
		<script src="js/jquery-2.1.0.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/SmoothScroll.min.js"></script>
		<script src="js/typed.js"></script>
		<script src="js/jquery.nav.js"></script>
		<script src="js/jquery.stellar.js"></script>
		<script src="js/jquery.flexslider-min.js"></script>
		<script src="js/jquery.placeholder.js"></script>
		<script src="js/jquery.accordion.js"></script>
		<script src="js/owl.carousel.min.js"></script>
		<script src="js/fancySelect.js"></script>
		<script src="js/wow.min.js"></script>
		<script src="js/gmap3.min.js"></script>
		<script src="js/main.min.js"></script>
	

</body></html>
